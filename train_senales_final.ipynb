{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKO_VHA6loDR"
      },
      "source": [
        "# Leonardo Gracida Munoz A01379812\n",
        "# Nancy L. García Jiménez A01378043\n",
        "## Red neuronal detectora de senales de trafico\n",
        "Link hacia dataset grande (DATASET) usada en drive:<br>\n",
        "https://drive.google.com/drive/folders/1fA9DtcOlEPpT_WcOAAgDyHBUZyQvRG0R?usp=sharing<br>\n",
        "Link hacia dataset pequena (dataset_red) usada en drive:<br>\n",
        "https://drive.google.com/drive/folders/1-3hc9RzfkL2eOIG2YRX-q0-WGxtW_DMA?usp=sharing\n",
        "\n",
        "Sitio original de la dataset:<br>\n",
        "https://benchmark.ini.rub.de/gtsrb_news.html\n",
        "\n",
        "Link hacia repositorio donde esta el codigo para poder clasificar imagenes:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ei4v2E8OKpg",
        "outputId": "1f107fad-9f1f-4046-9452-6d28ba824deb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow==2.6.2 in /usr/local/lib/python3.7/dist-packages (2.6.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.2) (1.46.3)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.2) (3.7.4.3)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.2) (3.1.0)\n",
            "Requirement already satisfied: keras<2.7,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.2) (2.6.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.7,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.2) (2.6.0)\n",
            "Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.2) (5.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.2) (1.1.0)\n",
            "Requirement already satisfied: tensorboard<2.7,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.2) (2.6.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.2) (1.6.3)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.2) (1.15.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.2) (1.19.5)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.2) (3.17.3)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.2) (0.37.1)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.2) (0.15.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.2) (1.12)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.2) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.2) (1.1.2)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.2) (1.12.1)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.2) (3.3.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.2) (0.4.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow==2.6.2) (1.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow==2.6.2) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow==2.6.2) (1.8.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow==2.6.2) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow==2.6.2) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow==2.6.2) (3.3.7)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow==2.6.2) (0.4.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow==2.6.2) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow==2.6.2) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow==2.6.2) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow==2.6.2) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow==2.6.2) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow==2.6.2) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow==2.6.2) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow==2.6.2) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow==2.6.2) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow==2.6.2) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow==2.6.2) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow==2.6.2) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow==2.6.2) (2022.5.18.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow==2.6.2) (3.2.0)\n",
            "Thu Jun 16 04:11:40 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "#Importamos la libreria de tensorflow deseada\n",
        "!pip install tensorflow==2.6.2\n",
        "#mostramos la targeta grafica a usar\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8EjkNeNWoD_",
        "outputId": "d5e39a31-ab91-4a96-f6de-c0eeb5511eed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#Importamos la dataset de google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FaPL9HWEOvAJ"
      },
      "outputs": [],
      "source": [
        "def preprocessing(img):\n",
        "  \"\"\"Funcion que preporcesa la imagen a usar\"\"\"\n",
        "  img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "  img =cv2.equalizeHist(img)\n",
        "  i#mg=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  img = img/255\n",
        "  return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "S55ipLuhZusD",
        "outputId": "0fb7fdc3-96d0-41cb-d5ce-9048d48e87d8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'import zipfile\\nTMP_DATA_DIR = \"/content/drive/MyDrive/dataset_red\"\\nto_unpack = [\\n    (\"/content/drive/MyDrive/Train_red.zip\", TMP_DATA_DIR),\\n\\n]\\n \\nfor file, directory in to_unpack:\\n    print(\"Unzipping {} to {}...\".format(file, directory))\\n    with zipfile.ZipFile(file,\"r\") as zip_ref:\\n        zip_ref.extractall(directory)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "#Esto lo corremos una vez para poder extraer el zip del dataset en drive\n",
        "\"\"\"import zipfile\n",
        "TMP_DATA_DIR = \"/content/drive/MyDrive/dataset_red\"\n",
        "to_unpack = [\n",
        "    (\"/content/drive/MyDrive/Train_red.zip\", TMP_DATA_DIR),\n",
        "\n",
        "]\n",
        " \n",
        "for file, directory in to_unpack:\n",
        "    print(\"Unzipping {} to {}...\".format(file, directory))\n",
        "    with zipfile.ZipFile(file,\"r\") as zip_ref:\n",
        "        zip_ref.extractall(directory)\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHfCOx13OQnX",
        "outputId": "44f9e69d-4d51-452e-81ff-13feb79f3339"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.2\n",
            "Clases totales detectadas:  6\n",
            "Compilando modelo...\n",
            "Modelo compilado\n"
          ]
        }
      ],
      "source": [
        "#Importamos todas las librerias necesarias a usar\n",
        "import tensorflow as tf\n",
        "#Buscamos el gpu a usar\n",
        "tf.config.set_visible_devices([], 'GPU')\n",
        "print(tf.__version__)\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "def myModel(inputShape,clases):\n",
        "    \"\"\"Funcion que crea el modelo de la red neuronal obteniendo los paramteros\n",
        "    de el tamano de la imagen y el numero de clases a clasificar\"\"\"\n",
        "    #Selección de hiperparamteros                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
        "    # Tamano de los filtros a usar en los Conv2D                                                                                                                                                                                   \n",
        "    size_of_Filter=(5,5)                                                                                                                                                                                                         \n",
        "    size_of_Filter2=(3,3)                                                                                                                                                                                                        \n",
        "    # Tekes batches of 2x2 pixels and avg the  \n",
        "    # Tamamos batches de 2x2 para disminuir la informacion obtenida del Conv2D                                                                                                                                                                                  \n",
        "    size_of_pool=(2,2)                                                                                                                                                                                                           \n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(60, size_of_Filter,input_shape=inputShape))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(BatchNormalization(axis=-1))\n",
        "    model.add(Conv2D(60, size_of_Filter))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(BatchNormalization(axis=-1))\n",
        "    model.add(MaxPooling2D(pool_size=size_of_pool))\n",
        "    model.add(Conv2D(30, size_of_Filter2))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(BatchNormalization(axis=-1))\n",
        "    model.add(Conv2D(30, size_of_Filter2))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(BatchNormalization(axis=-1))\n",
        "    model.add(MaxPooling2D(pool_size=size_of_pool))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(500))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(clases))\n",
        "    model.add(Activation(\"softmax\"))  \n",
        "    model.compile(optimizer=tf.keras.optimizers.RMSprop(),                                                                                                                                                                       \n",
        "              loss=tf.keras.losses.BinaryCrossentropy(),                                                                                                                                                                         \n",
        "              metrics=[tf.keras.metrics.BinaryAccuracy(),                                                                                                                                                                        \n",
        "                       tf.keras.metrics.FalseNegatives()]) \n",
        "    return model\n",
        "#Path de la carpeta donde se encuentra el DATASET a utilizar\n",
        "path = \"/content/drive/MyDrive/dataset_red/Train\" #En caso de que quieras entrenar la deteccion de 6 senales diferentes\n",
        "#path = \"/content/drive/MyDrive/DATASETrain\" #En caso de que quieras detectar 43 senales diferentes\n",
        "myList = os.listdir(path)\n",
        "print(\"Clases totales detectadas: \",len(myList))\n",
        "clases = len(myList)\n",
        "#Dimensiones de la imagen a usar\n",
        "imageDimesions = (32,32,1)\n",
        "#Creamos el modelo\n",
        "model = myModel(imageDimesions,clases)\n",
        "#Construimos el modelo\n",
        "model.build()\n",
        "#El tamano de lote a usar \n",
        "batch_size_val=16\n",
        "#El numero de epochs s usar\n",
        "epochs_val= 100\n",
        "testRatio = 0.2 #Proporcion de en cuanto vamos a dividir el DATASET el train y test\n",
        "gamma = 1     #Factor de crecimiento de aprendizaje\n",
        "learningRate = gamma * 1e-3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-qqml9AXF_7",
        "outputId": "49074bde-323f-48ae-eec1-d6ff7038bd5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importando Imagenes: \n",
            "0 1 2 3 4 5 "
          ]
        }
      ],
      "source": [
        "#Extraemos las imagenes de la carpeta del dataset con cv2\n",
        "count = 0\n",
        "images = []\n",
        "classNo = []\n",
        "print(\"Importando Imagenes: \")\n",
        "for i in myList:\n",
        "    imageList = os.path.join(path,i)\n",
        "    for j in os.listdir(imageList):\n",
        "        imgPath = os.path.join(imageList,j)\n",
        "        label = i\n",
        "        curImg = cv2.imread(imgPath)\n",
        "        #Le cambiamos el tamano a la imagen\n",
        "        curImg = cv2.resize(curImg,(imageDimesions[1],imageDimesions[0]))\n",
        "        #Preprocesamos la imagen\n",
        "        curImg = preprocessing(curImg)\n",
        "        curImg = np.expand_dims(curImg, axis=0)\n",
        "        curImg = np.transpose(curImg, (1, 2, 0))\n",
        "        images.append(curImg)\n",
        "        classNo.append(int(i))\n",
        "    print(count, end =\" \")\n",
        "    count +=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcuPCIQzhf0Z",
        "outputId": "bb7af223-0650-43fd-f4e5-fe61828636b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numero de imagenes importadas:  4693\n",
            "Dimensiones de las imgenes extraidas:  (4693, 32, 32, 1)\n",
            "2.6.2\n"
          ]
        }
      ],
      "source": [
        "print(\"Numero de imagenes importadas: \",len(images))\n",
        "images = np.array(images)\n",
        "print(\"Dimensiones de las imgenes extraidas: \",images.shape)\n",
        "classNo = np.array(classNo)\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uldsRfOXcMC",
        "outputId": "5258cb6a-0269-4164-dd39-b425bddf5e44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels en modo categorical\n",
            "(3754, 6)\n",
            "(939, 6)\n",
            "Proporcion de cada tipo de muestra en el dateset usado:\n",
            "[1.2427821 4.9842105 1.2063694 2.4790576 1.        1.3764535]\n"
          ]
        }
      ],
      "source": [
        "#Dividimos la dataset en una parte para train y otra parte para test\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, classNo, test_size=testRatio)\n",
        "#Cambismos los labels a modo categorical\n",
        "y_test = to_categorical(y_test, clases)\n",
        "y_train = to_categorical(y_train, clases)\n",
        "print(\"Labels en modo categorical\")\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "classTotal = y_train.sum(axis=0)\n",
        "classWeight = classTotal.max() / classTotal\n",
        "print(\"Proporcion de cada tipo de muestra en el dateset usado:\")\n",
        "print(classWeight)\n",
        "classWeight = {i: classWeight[i] for i in range(len(classWeight))}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXS6AYQohoHB",
        "outputId": "ac6ee04c-e333-4240-990c-32ff4c3fd45c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resumen de modelo de la red neuronal:\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 28, 28, 60)        1560      \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 28, 28, 60)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 28, 28, 60)        240       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 24, 24, 60)        90060     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 24, 24, 60)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 24, 24, 60)        240       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 12, 12, 60)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 10, 10, 30)        16230     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 10, 10, 30)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 10, 10, 30)        120       \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 8, 8, 30)          8130      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 8, 8, 30)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 8, 8, 30)          120       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 4, 4, 30)          0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 4, 4, 30)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 480)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 500)               240500    \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6)                 3006      \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 6)                 0         \n",
            "=================================================================\n",
            "Total params: 360,206\n",
            "Trainable params: 359,846\n",
            "Non-trainable params: 360\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(\"Resumen de modelo de la red neuronal:\")\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yaF6K489iYpO"
      },
      "outputs": [],
      "source": [
        "#Generacion de ruido en las imagenes\n",
        "dataGen = ImageDataGenerator(\n",
        "    rotation_range=5,\n",
        "    zoom_range=0.1,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.15,\n",
        "    fill_mode=\"nearest\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhsvS_t2hr8Q",
        "outputId": "6ff8d224-a0eb-40cc-fc4a-da6d38892645"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "235/235 [==============================] - 24s 99ms/step - loss: 0.2291 - binary_accuracy: 0.9216 - false_negatives: 1023.0000 - val_loss: 0.4930 - val_binary_accuracy: 0.7755 - val_false_negatives: 697.0000\n",
            "Epoch 2/100\n",
            "235/235 [==============================] - 24s 100ms/step - loss: 0.0811 - binary_accuracy: 0.9748 - false_negatives: 308.0000 - val_loss: 0.1156 - val_binary_accuracy: 0.9542 - val_false_negatives: 138.0000\n",
            "Epoch 3/100\n",
            "235/235 [==============================] - 23s 98ms/step - loss: 0.0534 - binary_accuracy: 0.9837 - false_negatives: 190.0000 - val_loss: 0.0159 - val_binary_accuracy: 0.9957 - val_false_negatives: 13.0000\n",
            "Epoch 4/100\n",
            "235/235 [==============================] - 23s 98ms/step - loss: 0.0405 - binary_accuracy: 0.9883 - false_negatives: 137.0000 - val_loss: 0.0570 - val_binary_accuracy: 0.9870 - val_false_negatives: 38.0000\n",
            "Epoch 5/100\n",
            "235/235 [==============================] - 23s 99ms/step - loss: 0.0298 - binary_accuracy: 0.9919 - false_negatives: 93.0000 - val_loss: 0.0151 - val_binary_accuracy: 0.9941 - val_false_negatives: 17.0000\n",
            "Epoch 6/100\n",
            "235/235 [==============================] - 23s 98ms/step - loss: 0.0279 - binary_accuracy: 0.9921 - false_negatives: 91.0000 - val_loss: 0.0261 - val_binary_accuracy: 0.9938 - val_false_negatives: 18.0000\n",
            "Epoch 7/100\n",
            "235/235 [==============================] - 23s 98ms/step - loss: 0.0245 - binary_accuracy: 0.9935 - false_negatives: 75.0000 - val_loss: 0.0232 - val_binary_accuracy: 0.9925 - val_false_negatives: 21.0000\n",
            "Epoch 8/100\n",
            "235/235 [==============================] - 23s 98ms/step - loss: 0.0198 - binary_accuracy: 0.9945 - false_negatives: 62.0000 - val_loss: 0.0090 - val_binary_accuracy: 0.9977 - val_false_negatives: 7.0000\n",
            "Epoch 9/100\n",
            "235/235 [==============================] - 23s 98ms/step - loss: 0.0176 - binary_accuracy: 0.9963 - false_negatives: 43.0000 - val_loss: 0.2838 - val_binary_accuracy: 0.9215 - val_false_negatives: 226.0000\n",
            "Epoch 10/100\n",
            "235/235 [==============================] - 23s 99ms/step - loss: 0.0171 - binary_accuracy: 0.9956 - false_negatives: 51.0000 - val_loss: 0.0095 - val_binary_accuracy: 0.9963 - val_false_negatives: 11.0000\n",
            "Epoch 11/100\n",
            "235/235 [==============================] - 23s 99ms/step - loss: 0.0218 - binary_accuracy: 0.9952 - false_negatives: 54.0000 - val_loss: 0.0078 - val_binary_accuracy: 0.9975 - val_false_negatives: 7.0000\n",
            "Epoch 12/100\n",
            "235/235 [==============================] - 23s 98ms/step - loss: 0.0180 - binary_accuracy: 0.9945 - false_negatives: 64.0000 - val_loss: 0.0387 - val_binary_accuracy: 0.9886 - val_false_negatives: 32.0000\n",
            "Epoch 13/100\n",
            "235/235 [==============================] - 23s 98ms/step - loss: 0.0115 - binary_accuracy: 0.9973 - false_negatives: 30.0000 - val_loss: 0.1087 - val_binary_accuracy: 0.9771 - val_false_negatives: 65.0000\n",
            "Epoch 14/100\n",
            "235/235 [==============================] - 24s 101ms/step - loss: 0.0151 - binary_accuracy: 0.9962 - false_negatives: 44.0000 - val_loss: 0.1429 - val_binary_accuracy: 0.9691 - val_false_negatives: 89.0000\n"
          ]
        }
      ],
      "source": [
        "_#Entrenamos el modelo\n",
        "from keras.callbacks import EarlyStopping\n",
        "#Creamos un callback para evitar overfiting\n",
        "monitor_val_acc = EarlyStopping(monitor = 'val_loss', patience = 3)\n",
        "H=model.fit(dataGen.flow(X_train,y_train,batch_size=batch_size_val),epochs=epochs_val,validation_data=(X_test,y_test),shuffle=1,callbacks=[monitor_val_acc])\n",
        "#Salvamos el modelo\n",
        "model.save('/content/drive/MyDrive/OUTPUT/signals_5_super_final')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "train_senales_final.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}